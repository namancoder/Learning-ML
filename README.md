# Learning-ML






<!-- toc -->



- [Exploratory Data Analysis of Iris Flower Data Set](#Exploratory_Data_Analysis_of_Iris_Flower_Data_Set)
- [Haberman Survival Dataset](#Haberman_Survival_Dataset)
- [Probability & Statistic](#Probability_and_Statistics)
- [Visualization and Dimensionality Reduction](#Visualization_and_Dimensionality_Reduction)
- [NLP AND ML Foundation](#NLP_AND_ML)
  * [KNN](#KNN)



<!-- toc -->

## Exploratory_Data_Analysis_of_Iris_Flower_Data_Set

Univariate(PDF,CDF,BoxPlot,Violin Plot) and bivariate form(Scatter, PairPlot) of analysis

## Haberman_Survival_Dataset

Number of Instances: 306

Number of Attributes: 4 (including the class attribute)

Attribute Information:

Age of patient at time of operation (numerical)
Patient's year of operation (year - 1900, numerical)
Number of positive axillary nodes detected (numerical)
Survival status (class attribute)
1 = the patient survived 5 years or longer
2 = the patient died within 5 year
Missing Attribute Values: None

[Kaggle Link] (https://www.kaggle.com/devilbenign/haberman-ds)

## Probability_and_Statistics
Learnt so many mathematical theorems and distributions like Gaussian,Uniform,Bernoulli,Binomial,Log Normal,Pareta.

Central Limit theorem,Confidence Interval,  Power Law, Q-Q Plots,Chebyshevs Inequality, Hypothesis Testing , KS-Test,,Resampling & Permutation Test.

## Visualization_and_Dimensionality_Reduction
Handled the 784 dimension MNIST dataset(felt pretty cool actuallyðŸ˜)\


Also learnt about Data Preprocessing which is a must porcess before data analysis
Columnn Normalization and Standardization\

also worked on FASHION MNIST dataset which is the "Hello world" of modern ML ---> [LINK](https://colab.research.google.com/drive/1FNRGJur7gtauKyt4tY-JrD26Vaso4i0a?usp=sharing)

PCA and t-SNE for Dimensionality Reduction

## NLP_AND_ML
Currently learning about classification and regreesion algo KNN
[TF-IDF Implementation withot SkLearn](https://colab.research.google.com/drive/12Kf8PEo2QxH7rOLo79mKaiMt9US6iugJ?usp=sharing)

### KNN
Cosine Similarity & Distance ,Types of distances, Effectiveness, Over & Under-Fitting , Simple & K-Fold Cross Validation , Timebase splitting ,Weighted KNN , KD-Tree , Locality Sensitive Hashing for Cosine Similarity and Euclidean Distance.
[NOTEBOOK](https://colab.research.google.com/drive/1CGUdnslVkKD_7sjaqyIXmOmYXJj9SEAC?usp=sharing)

------------------
## DEEP_LEARNING
 - Playing with MNIST Data Set using Sequential Model and Adam optimizer, also used CallBacks [Link]()
 - Using Convolutions in our DNN to better the accuracy (2 Conv2d layers and MaxPooling) 
 - Real World images classfication (happy or Sad dataset -40 Happy & 40 Sad) preprocessing with ImageDataGenerator where target_size = (150,150
 




